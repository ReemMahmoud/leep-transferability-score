{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "leep-score.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPzwRkr/a2Rz9n09nQ9Bot7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReemMahmoud/leep-transferability-score/blob/main/leep_score.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Transferability Estimation Problem\n",
        "\n",
        "In this notebook, we dissect the formulation of LEEP - the Log Expected Empirical Prediction - score from the paper titled \"LEEP: A New Measure to Evaluate Transferability of Learned Representations\" by C. Nguyen et al. published at ICML 2020."
      ],
      "metadata": {
        "id": "N7rA1JLDrnqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LEEP full code implementation\n",
        "\n",
        "Source: https://github.com/thuml/LogME/blob/main/LEEP.py"
      ],
      "metadata": {
        "id": "3zVTsRVCsF4w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izITHnst0EbZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def LEEP(pseudo_source_label: np.ndarray, target_label: np.ndarray):\n",
        "    \"\"\"\n",
        "    :param pseudo_source_label: shape [N, C_s]\n",
        "    :param target_label: shape [N], elements in [0, C_t)\n",
        "    :return: leep score\n",
        "    \"\"\"\n",
        "    N, C_s = pseudo_source_label.shape\n",
        "    target_label = target_label.reshape(-1)\n",
        "    C_t = int(np.max(target_label) + 1)   # the number of target classes\n",
        "    normalized_prob = pseudo_source_label / float(N)  # sum(normalized_prob) = 1\n",
        "    joint = np.zeros((C_t, C_s), dtype=float)  # placeholder for joint distribution over (y, z)\n",
        "    for i in range(C_t):\n",
        "        this_class = normalized_prob[target_label == i]\n",
        "        row = np.sum(this_class, axis=0)\n",
        "        joint[i] = row # P (y , z)\n",
        "    p_target_given_source = (joint / joint.sum(axis=0, keepdims=True)).T  # P(y | z)\n",
        "\n",
        "    empirical_prediction = pseudo_source_label @ p_target_given_source\n",
        "    empirical_prob = np.array([predict[label] for predict, label in zip(empirical_prediction, target_label)])\n",
        "    leep_score = np.mean(np.log(empirical_prob))\n",
        "    return leep_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Breakdown\n",
        "\n",
        "In the remainder of the notebook, we dissect the above code implementation of LEEP with a dummy example to understand:\n",
        "\n",
        "*   What computations are taking place\n",
        "*   How these computations render a score that reflects transferability across tasks\n",
        "\n"
      ],
      "metadata": {
        "id": "uYbWkQ1KsO7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the givens:\n",
        "\n",
        "\n",
        "*   Y = target labels\n",
        "*   Z = pseudo source labels (or 'dummy' labels)\n",
        "*   C_t = No. of labels in target task (counting from index 0)\n",
        "*   C_s = No. of labels in source task (counting from index 0)\n",
        "*   N = No. of samples in target dataset\n"
      ],
      "metadata": {
        "id": "3jcMGNNas8BS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dummy Example 1:\n",
        "\n",
        "We will define a dummy example to follow through the computations of LEEP in a simple way. This includes a:\n",
        "1. Target dataset with 10 data samples (N=10)\n",
        "2. Target task with 5 labels (C_t=5)\n",
        "3. Source task with 4 labels (C_s=4)"
      ],
      "metadata": {
        "id": "0QdjtSKHtiBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a column reflecting the target output variable (Y) with 5 labels \n",
        "target_label = np.array([0, 2, 4, 4, 1, 1, 3, 0, 0, 2]) # C_t = 5, N = 10\n",
        "target_label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1T53IvI0Jcs",
        "outputId": "07e9595a-cca2-4cba-e5c0-2d8a8b86d0c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a matrix of pseudo source labels that is generated from a forward pass of the target data samples through the pre-trained network\n",
        "# pseudo source label matrix has 10 instances of predictions (since N=10) with label distribution across 4 labels \n",
        "#     Note: (doesn't have to be one-hot encoded. We could take output probabilities of the output layer prior to softmax.)\n",
        "pseudo_source_label = np.array([[0, 0, 0, 1],\n",
        "                               [0, 1, 0, 0],\n",
        "                               [0, 1, 0, 0],\n",
        "                               [0, 0, 1, 0],\n",
        "                               [0, 1, 0, 0],\n",
        "                               [1, 0, 0, 0],\n",
        "                               [1, 0, 0, 0],\n",
        "                               [0, 0, 0, 1],\n",
        "                               [0, 0, 0, 1],\n",
        "                               [1, 0, 0, 0]]) # C_s = 4, N = 10\n",
        "pseudo_source_label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5yo8FY30v3N",
        "outputId": "1fedf3a6-d17b-4eb7-9cfa-4e9a9dc7b09f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just for fun, let's compute the LEEP score across the dummy example sets:\n",
        "LEEP(pseudo_source_label, target_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1OYnLMa2OLT",
        "outputId": "6215b291-64df-430c-bbfe-c7a06e48841c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.6591673732008659"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The LEEP score is always a negative value. The LARGER the score, the better the transferability across tasks. "
      ],
      "metadata": {
        "id": "8BPQcFJjvMF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining parameters N, C_s, C_t \n",
        "N, C_s = pseudo_source_label.shape\n",
        "C_t = int(np.max(target_label) + 1)\n",
        "print(f' Size of dataset = {N} \\n Size of target labels = {C_t} \\n Size of source labels = {C_s}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW8blL3Z2v6d",
        "outputId": "cf0c420a-8525-4383-aa1b-6be507d6cc20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Size of dataset = 10 \n",
            " Size of target labels = 5 \n",
            " Size of source labels = 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshaping, although we don't need it here. (\n",
        "# Disclaimer: I still need to look into why we're reshaping. What shape is being expected into the function, though they define it as a vectorized input?? Any thoughts?\n",
        "target_label = target_label.reshape(-1)\n",
        "target_label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO7ALc263FBF",
        "outputId": "c04a01ec-fc3a-44cc-a85e-b597a7dd3939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizing the dummy labels since we're going to average both P(y,z) and P(z) by dividing through with 1/N. \n",
        "normalized_prob = pseudo_source_label / float(N) # Note: sum(normalized_prob) = 1\n",
        "normalized_prob                                  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0IWj1rv3Fox",
        "outputId": "95561468-3a42-4efc-9a99-20fbd6810177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0. , 0. , 0. , 0.1],\n",
              "       [0. , 0.1, 0. , 0. ],\n",
              "       [0. , 0.1, 0. , 0. ],\n",
              "       [0. , 0. , 0.1, 0. ],\n",
              "       [0. , 0.1, 0. , 0. ],\n",
              "       [0.1, 0. , 0. , 0. ],\n",
              "       [0.1, 0. , 0. , 0. ],\n",
              "       [0. , 0. , 0. , 0.1],\n",
              "       [0. , 0. , 0. , 0.1],\n",
              "       [0.1, 0. , 0. , 0. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a placeholder for the joint distribution, P(y, z), that we'll compute soon\n",
        "joint = np.zeros((C_t, C_s), dtype=float)  \n",
        "print(joint.shape)\n",
        "print(joint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "donIARZA3sKn",
        "outputId": "500fbc66-805a-48cf-d3e7-525a7f4b4bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 4)\n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Breakdown of one iteration of loop to compute the joint probability P(y,z):\n",
        "\n",
        "We're about to go through one broken down iteration of the following loop that computes P(y,z):\n",
        "\n",
        "\n",
        "```\n",
        "for i in range(C_t):\n",
        "  this_class = normalized_prob[target_label == i]\n",
        "  row = np.sum(this_class, axis=0)\n",
        "  joint[i] = row\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "XwMpZbZNxdpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0 # for label = 0 \n",
        "this_class = normalized_prob[target_label == i] # we're going to select the normalized prob rows at the indicies where the target label column has the label '0'\n",
        "this_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGWCC-Wv5Gnf",
        "outputId": "703b6dff-ffad-48fd-dc5b-1f028757be44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0. , 0. , 0. , 0.1],\n",
              "       [0. , 0. , 0. , 0.1],\n",
              "       [0. , 0. , 0. , 0.1]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you're confused, let's put things side to side\n",
        "\n",
        "We want to look at the normlized probability (which remember: is the normalized dummy source labels matrix) at the rows for the true target label (or class, thus the variable name \"this_class\") of '0'.\n",
        "\n",
        "\n",
        "```\n",
        "target_label = \n",
        "      np.array([0, 2, 4, 4, 1, 1, 3, 0, 0, 2])\n",
        "```\n",
        "\n",
        "We can see that label '0' exists at indicies: 0, 7, 8\n",
        "\n",
        "```\n",
        "this_class = \n",
        "array([[0. , 0. , 0. , 0.1],\n",
        "       [0. , 0. , 0. , 0.1],\n",
        "       [0. , 0. , 0. , 0.1]])\n",
        "```\n",
        "You can now understand that `this_class` captured the rows from `normalized_prob` at indicies: 0, 7, 8. \n",
        "\n",
        "See `normalized_prob` for reference below.\n",
        "\n",
        "```\n",
        "normalized_prob = \n",
        "array([[0. , 0. , 0. , 0.1],\n",
        "       [0. , 0.1, 0. , 0. ],\n",
        "       [0. , 0.1, 0. , 0. ],\n",
        "       [0. , 0. , 0.1, 0. ],\n",
        "       [0. , 0.1, 0. , 0. ],\n",
        "       [0.1, 0. , 0. , 0. ],\n",
        "       [0.1, 0. , 0. , 0. ],\n",
        "       [0. , 0. , 0. , 0.1],\n",
        "       [0. , 0. , 0. , 0.1],\n",
        "       [0.1, 0. , 0. , 0. ]])\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e5pUmwyTyC9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sum across axis = 0 (through each column, summing value of all rows)\n",
        "row = np.sum(this_class, axis=0) \n",
        "row"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWeBfoCX5J3z",
        "outputId": "46718f96-e4e6-4a78-c2e1-aba8ec6404ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0. , 0. , 0. , 0.3])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we replace the first row of the joint with the resulting summation from the prior step\n",
        "joint[i] = row\n",
        "joint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pnPERPc4QE6",
        "outputId": "dfa06791-45c6-47e0-9e00-002fbca90b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0. , 0. , 0. , 0.3],\n",
              "       [0. , 0. , 0. , 0. ],\n",
              "       [0. , 0. , 0. , 0. ],\n",
              "       [0. , 0. , 0. , 0. ],\n",
              "       [0. , 0. , 0. , 0. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Et Voila!**\n",
        "\n",
        "That's the computation of the joint probability P(y,z) over one iteration.\n",
        "\n",
        "Next, we will run the loop to compute all rows of P(y,z).\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ZHWS_vE_aV03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the full P(y,z) matrix\n",
        "for i in range(C_t):\n",
        "  this_class = normalized_prob[target_label == i]\n",
        "  row = np.sum(this_class, axis=0)\n",
        "  joint[i] = row\n",
        "\n",
        "joint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNv1MepH5ujW",
        "outputId": "37612377-df05-487e-e163-b91bff6d0f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0. , 0. , 0. , 0.3],\n",
              "       [0.1, 0.1, 0. , 0. ],\n",
              "       [0.1, 0.1, 0. , 0. ],\n",
              "       [0.1, 0. , 0. , 0. ],\n",
              "       [0. , 0.1, 0.1, 0. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute the conditional probability P(y|z)\n",
        "\n",
        "P(y|z) = P(y,z) / P(z)\n",
        "\n",
        "We already computed P(y,z) in the previous step.\n",
        "\n",
        "Now, we need to compute P(z) then divide to get the resulting P(y|z)."
      ],
      "metadata": {
        "id": "lBz1159HanBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the marginal probability P(z) by simply summing across axis=0 of the joint P(y,z)\n",
        "joint_sum = joint.sum(axis=0, keepdims=True)\n",
        "joint_sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbPbFwoh5mT-",
        "outputId": "b8cda2eb-279e-41c9-aba1-646035d2a1b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3, 0.3, 0.1, 0.3]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joint / joint_sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE83VtQY55Xw",
        "outputId": "73046df7-0f45-4bad-9540-e54b7d5a754e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 1.        ],\n",
              "       [0.33333333, 0.33333333, 0.        , 0.        ],\n",
              "       [0.33333333, 0.33333333, 0.        , 0.        ],\n",
              "       [0.33333333, 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.33333333, 1.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the conditional probability P(y|z): P(y,z)/P(z)\n",
        "\n",
        "p_target_given_source = (joint / joint.sum(axis=0, keepdims=True))\n",
        "p_target_given_source"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg8oKUZD52uS",
        "outputId": "c3bc5edd-2c4b-4ec6-d3d3-d085fc3ff7fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 1.        ],\n",
              "       [0.33333333, 0.33333333, 0.        , 0.        ],\n",
              "       [0.33333333, 0.33333333, 0.        , 0.        ],\n",
              "       [0.33333333, 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.33333333, 1.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pseudo_source_label @ p_target_given_source"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKj4W8jk6WdB",
        "outputId": "f0d8ba74-a901-4033-866c-eb5448e562ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.33333333, 0.33333333, 0.        , 0.33333333],\n",
              "       [0.        , 0.33333333, 0.33333333, 0.        , 0.33333333],\n",
              "       [0.        , 0.        , 0.        , 0.        , 1.        ],\n",
              "       [0.        , 0.33333333, 0.33333333, 0.        , 0.33333333],\n",
              "       [0.        , 0.33333333, 0.33333333, 0.33333333, 0.        ],\n",
              "       [0.        , 0.33333333, 0.33333333, 0.33333333, 0.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.33333333, 0.33333333, 0.33333333, 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute the LEEP score\n",
        "\n",
        "#### Start by computing the empirical predictor result = pseudo_source_label @ p_target_given_source"
      ],
      "metadata": {
        "id": "zhbr5WQ9b_aB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pseudo_source_label.shape)\n",
        "print(p_target_given_source.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ezz5V48_cO_u",
        "outputId": "fcba6843-ac3a-48dd-dc4a-01dcd5a3be93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 4)\n",
            "(5, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to transpose p_target_given_source in order to get dimensions (4x5) and successfully implement the matrix multiplication for the empirical predictor."
      ],
      "metadata": {
        "id": "kKUYp87qcTAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "empirical_prediction = pseudo_source_label @ (p_target_given_source).T\n",
        "print(empirical_prediction.shape)\n",
        "print(empirical_prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl2_8UHJ6bUs",
        "outputId": "8294dec9-1a5f-4072-9f99-fb3cf112b54c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 5)\n",
            "[[1.         0.         0.         0.         0.        ]\n",
            " [0.         0.33333333 0.33333333 0.         0.33333333]\n",
            " [0.         0.33333333 0.33333333 0.         0.33333333]\n",
            " [0.         0.         0.         0.         1.        ]\n",
            " [0.         0.33333333 0.33333333 0.         0.33333333]\n",
            " [0.         0.33333333 0.33333333 0.33333333 0.        ]\n",
            " [0.         0.33333333 0.33333333 0.33333333 0.        ]\n",
            " [1.         0.         0.         0.         0.        ]\n",
            " [1.         0.         0.         0.         0.        ]\n",
            " [0.         0.33333333 0.33333333 0.33333333 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our empirical predictor results in a (10x5) matrix:\n",
        "- predictions across 10 samples\n",
        "- 5 categories for the prediction (matching our target task class count)"
      ],
      "metadata": {
        "id": "nCgsaqb_cgj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGBEm4qJ6mVl",
        "outputId": "401e3387-88b5-4e31-81d0-93aa9c9d61c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 4, 4, 1, 1, 3, 0, 0, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute a empirical predictor vector of label probabilities for each of the 10 samples\n",
        "# Note: matching the dimention of our target_label\n",
        "\n",
        "empirical_prob = np.array([predict[label] for predict, label in zip(empirical_prediction, target_label)])\n",
        "print(empirical_prob.shape)\n",
        "print(empirical_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ5mQjUz7EKs",
        "outputId": "eb680728-f90d-4a11-d27f-88a3061cb3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10,)\n",
            "[1.         0.33333333 0.33333333 1.         0.33333333 0.33333333\n",
            " 0.33333333 1.         1.         0.33333333]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More explanation:\n",
        "\n",
        "The empirical probability is looking at the probability generated by the expected empirical predictor (EEP) for each TRUE label in target_label.\n",
        "\n",
        "So, again, let's put things side-by-side to see them clearly.\n",
        "\n",
        "```\n",
        "target_label = \n",
        "      np.array([0, 2, 4, 4, 1, 1, 3, 0, 0, 2])\n",
        "```\n",
        "```\n",
        "empirical_prediction = \n",
        "[[1.         0.         0.         0.         0.        ]\n",
        " [0.         0.33333333 0.33333333 0.         0.33333333]\n",
        " [0.         0.33333333 0.33333333 0.         0.33333333]\n",
        " [0.         0.         0.         0.         1.        ]\n",
        " [0.         0.33333333 0.33333333 0.         0.33333333]\n",
        " [0.         0.33333333 0.33333333 0.33333333 0.        ]\n",
        " [0.         0.33333333 0.33333333 0.33333333 0.        ]\n",
        " [1.         0.         0.         0.         0.        ]\n",
        " [1.         0.         0.         0.         0.        ]\n",
        " [0.         0.33333333 0.33333333 0.33333333 0.        ]]\n",
        " ```\n",
        "\n",
        "**To get the `empirical_prob`, we want to answer:**\n",
        "\n",
        "For each row of `empirical_prediction`, what is the probability of the true label from `target_label`?\n",
        "\n",
        "\n",
        "Example:\n",
        "```\n",
        "# First iteration\n",
        "For first row of empirical_prediction = [1. 0. 0. 0. 0. ]\n",
        "empirical_prediction[label=0] = 1\n",
        "\n",
        "# Second iteration\n",
        "For second row of empirical_prediction = [0. 0.333 0.333 0. 0.333]\n",
        "empirical_prediction[label=1] = 0.333\n",
        "\n",
        "Etc.\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Building our intuition: \n",
        "\n",
        "We are seeing how close are the empirical predictor probabilities to the true target labels. \n",
        "\n",
        "This will give a sense of how close the source dummy labels are from the true labels, which in return measures how close are the source and target tasks semantics. \n",
        "\n",
        "We use this to decide whether we will get successful knowledge transfer between source and target tasks.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5B5Z-FvYdQcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute LEEP\n"
      ],
      "metadata": {
        "id": "5Xjn-_iugDHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute LEEP by averaging across the log of the empirical probabilities\n",
        "leep_score = np.mean(np.log(empirical_prob))\n",
        "leep_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtxZYmL9rG9L",
        "outputId": "781009de-e912-48ce-9c11-312312033287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.6591673732008659"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We won't be able to justify or make much sense out of this score since we're working with a dummy example.\n",
        "\n",
        "Let's try out a test where our source dummy labels are exactly matching our true target labels.\n",
        "\n",
        "**We should expect to see a LEEP score = 0**"
      ],
      "metadata": {
        "id": "60P_o9SjgFvJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dummy example 2"
      ],
      "metadata": {
        "id": "ET_lNKUzgS5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_label = np.array([0, 2, 4, 4, 1, 1, 3, 0, 0, 2]) # C_t = 5, N = 10\n",
        "target_label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIFdEPLvgYDm",
        "outputId": "ec5c7c31-d901-422d-d3f3-f4b4991a6c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for the sake of the dummy example, we use the same number of labels across source and target tasks\n",
        "pseudo_source_label = np.array([[1, 0, 0, 0, 0],\n",
        "                               [0, 0, 1, 0, 0],\n",
        "                               [0, 0, 0, 0, 1],\n",
        "                               [0, 0, 0, 0, 1],\n",
        "                               [0, 1, 0, 0, 0],\n",
        "                               [0, 1, 0, 0, 0],\n",
        "                               [0, 0, 0, 1, 0],\n",
        "                               [1, 0, 0, 0, 0],\n",
        "                               [1, 0, 0, 0, 0],\n",
        "                               [0, 0, 1, 0, 0]]) # C_s = 5, N = 10\n",
        "pseudo_source_label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjIQO9IggYsz",
        "outputId": "71b25b5a-81af-46f8-b482-96726f145104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check and verify that LEEP will = 0 \n",
        "LEEP(pseudo_source_label, target_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltpmx2e3gx_r",
        "outputId": "76911098-6184-4a88-8569-3b40ed7c58a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected (Y) !"
      ],
      "metadata": {
        "id": "VVU3SaYAg3Pg"
      }
    }
  ]
}